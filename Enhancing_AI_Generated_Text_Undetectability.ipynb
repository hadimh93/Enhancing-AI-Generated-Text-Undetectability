{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMkSinu3gEtX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from gensim.models import Word2Vec\n",
        "import openai\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Enable inline plotting\n",
        "%matplotlib inline\n",
        "\n",
        "# Load main data\n",
        "files = ['dev_en_news', 'dev_en_reviews','dev_en_twitter', 'dev_nl_news', 'dev_nl_reviews', 'dev_nl_twitter']\n",
        "df_list = []\n",
        "\n",
        "for file in files:\n",
        "    # Extract 'lang' and 'domain' from filename\n",
        "    _, lang, domain = file.split(\"_\")\n",
        "    temp_df = pd.read_csv(f'Data/{file}.csv')\n",
        "    if 'label' not in temp_df.columns or 'text' not in temp_df.columns:\n",
        "        raise ValueError(f\"Missing required columns in file: {file}\")\n",
        "    temp_df['domain'] = domain\n",
        "    temp_df['lan'] = lang\n",
        "    df_list.append(temp_df)\n",
        "\n",
        "# Concatenate dataframes\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "df['source'] = 'CLIN33'\n",
        "df['label1'] = df['label'].apply(lambda label: 'generated' if label == 1 else 'human')\n",
        "\n",
        "# Drop rows with missing text or label\n",
        "df.dropna(subset=['text', 'label'], inplace=True)\n",
        "\n",
        "# Use all data\n",
        "data = df.copy()\n",
        "\n",
        "# Data preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text, lang):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    if lang == 'en':\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "    elif lang == 'nl':\n",
        "        stop_words = set(stopwords.words('dutch'))\n",
        "    else:\n",
        "        stop_words = set()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "data['processed_text'] = data.apply(lambda row: preprocess_text(row['text'], row['lan']), axis=1)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X = data[['processed_text', 'lan', 'domain']]\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train_text = X_train['processed_text']\n",
        "X_test_text = X_test['processed_text']\n",
        "\n",
        "# Vectorization using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
        "X_test_tfidf = vectorizer.transform(X_test_text)\n",
        "\n",
        "# Train XGBoost model\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluation\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Overall metrics\n",
        "print(\"Overall Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['human', 'generated']))\n",
        "\n",
        "# Prepare test results DataFrame\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "y_pred_series = pd.Series(y_pred, name='pred_label')\n",
        "test_results = pd.concat([X_test, y_test.rename('true_label'), y_pred_series], axis=1)\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return precision, recall, f1, accuracy\n",
        "\n",
        "# Metrics per language\n",
        "languages = test_results['lan'].unique()\n",
        "metrics_per_language = []\n",
        "\n",
        "for lang in languages:\n",
        "    subset = test_results[test_results['lan'] == lang]\n",
        "    precision, recall, f1, accuracy = calculate_metrics(subset['true_label'], subset['pred_label'])\n",
        "    metrics_per_language.append({'Language': lang, 'Precision': precision, 'Recall': recall, 'F1-Score': f1, 'Accuracy': accuracy})\n",
        "    print(f\"\\nClassification Report for language: {lang}\")\n",
        "    print(classification_report(subset['true_label'], subset['pred_label'], target_names=['human', 'generated']))\n",
        "\n",
        "metrics_lang_df = pd.DataFrame(metrics_per_language)\n",
        "\n",
        "# Plot metrics per language\n",
        "fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
        "metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy']\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    sns.barplot(x='Language', y=metric, data=metrics_lang_df, ax=ax[idx])\n",
        "    ax[idx].set_title(f'{metric} per Language')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Metrics per genre\n",
        "genres = test_results['domain'].unique()\n",
        "metrics_per_genre = []\n",
        "\n",
        "for genre in genres:\n",
        "    subset = test_results[test_results['domain'] == genre]\n",
        "    precision, recall, f1, accuracy = calculate_metrics(subset['true_label'], subset['pred_label'])\n",
        "    metrics_per_genre.append({'Genre': genre, 'Precision': precision, 'Recall': recall, 'F1-Score': f1, 'Accuracy': accuracy})\n",
        "    print(f\"\\nClassification Report for genre: {genre}\")\n",
        "    print(classification_report(subset['true_label'], subset['pred_label'], target_names=['human', 'generated']))\n",
        "\n",
        "metrics_genre_df = pd.DataFrame(metrics_per_genre)\n",
        "\n",
        "# Plot metrics per genre\n",
        "fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    sns.barplot(x='Genre', y=metric, data=metrics_genre_df, ax=ax[idx])\n",
        "    ax[idx].set_title(f'{metric} per Genre')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Metrics per language and genre\n",
        "metrics_per_lang_genre = []\n",
        "\n",
        "for lang in languages:\n",
        "    for genre in genres:\n",
        "        subset = test_results[(test_results['lan'] == lang) & (test_results['domain'] == genre)]\n",
        "        if len(subset) > 0:\n",
        "            precision, recall, f1, accuracy = calculate_metrics(subset['true_label'], subset['pred_label'])\n",
        "            metrics_per_lang_genre.append({'Language': lang, 'Genre': genre, 'Precision': precision, 'Recall': recall, 'F1-Score': f1, 'Accuracy': accuracy})\n",
        "            print(f\"\\nClassification Report for language: {lang}, genre: {genre}\")\n",
        "            print(classification_report(subset['true_label'], subset['pred_label'], target_names=['human', 'generated']))\n",
        "\n",
        "metrics_lang_genre_df = pd.DataFrame(metrics_per_lang_genre)\n",
        "\n",
        "# Pivot table for heatmap\n",
        "pivot_df = metrics_lang_genre_df.pivot(index='Language', columns='Genre', values='Accuracy')\n",
        "\n",
        "\n",
        "# Plot heatmap of accuracy per language and genre\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(pivot_df, annot=True, cmap='Blues')\n",
        "plt.title('Accuracy per Language and Genre')\n",
        "plt.show()\n",
        "\n",
        "# Explainability using SHAP\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# Convert the test data to dense format\n",
        "X_test_tfidf_dense = X_test_tfidf.toarray()\n",
        "\n",
        "# Get SHAP values\n",
        "shap_values = explainer.shap_values(X_test_tfidf_dense)\n",
        "\n",
        "# Identify influential tokens\n",
        "def get_influential_tokens(shap_values, vectorizer):\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    influential_tokens = []\n",
        "    for i in range(len(shap_values)):\n",
        "        token_importances = shap_values[i]\n",
        "        top_indices = np.argsort(np.abs(token_importances))[-5:]  # Top 5 tokens per sample\n",
        "        top_tokens = [feature_names[j] for j in top_indices]\n",
        "        influential_tokens.append(top_tokens)\n",
        "    return influential_tokens\n",
        "\n",
        "influential_tokens = get_influential_tokens(shap_values, vectorizer)\n",
        "\n",
        "# Save the most effective tokens\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)\n",
        "token_importance_df = pd.DataFrame({\n",
        "    'token': feature_names,\n",
        "    'mean_abs_shap_value': mean_abs_shap_values\n",
        "})\n",
        "token_importance_df = token_importance_df.sort_values(by='mean_abs_shap_value', ascending=False)\n",
        "token_importance_df.to_csv('most_effective_tokens.csv', index=False)\n",
        "\n",
        "# Plot the top 20 most important tokens\n",
        "top_tokens_df = token_importance_df.head(20)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='mean_abs_shap_value', y='token', data=top_tokens_df, orient='h')\n",
        "plt.title('Top 20 Most Important Tokens')\n",
        "plt.xlabel('Mean Absolute SHAP Value')\n",
        "plt.ylabel('Token')\n",
        "plt.show()\n",
        "\n",
        "# SHAP summary plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(shap_values, features=X_test_tfidf_dense, feature_names=feature_names)\n",
        "plt.show()\n",
        "\n",
        "# Strategy 1: Replacing tokens with the most similar words used by humans\n",
        "# human_texts = data[data['label1'] == 'human']['processed_text']\n",
        "# human_tokens = [nltk.word_tokenize(text) for text in human_texts]\n",
        "# human_model = Word2Vec(human_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Use only the training data for the Word2Vec model\n",
        "human_texts_train = X_train[y_train == 0]['processed_text']\n",
        "human_tokens_train = [nltk.word_tokenize(text) for text in human_texts_train]\n",
        "human_model = Word2Vec(human_tokens_train, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "def replace_with_similar_human_word(text, tokens_to_replace):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    replacements = {}\n",
        "    for token in tokens:\n",
        "        if token in tokens_to_replace:\n",
        "            if token in human_model.wv:\n",
        "                similar_words = human_model.wv.most_similar(token, topn=1)\n",
        "                if similar_words:\n",
        "                    replacement = similar_words[0][0]\n",
        "                    text = text.replace(token, replacement, 1)\n",
        "                    replacements[token] = replacement\n",
        "    return text, replacements\n",
        "\n",
        "X_test_modified_1 = []\n",
        "replacements_strategy1 = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    text = X_test.iloc[i]['processed_text']\n",
        "    tokens_to_replace = influential_tokens[i]\n",
        "    modified_text, replacements = replace_with_similar_human_word(text, tokens_to_replace)\n",
        "    X_test_modified_1.append(modified_text)\n",
        "    replacements_strategy1.append(replacements)\n",
        "\n",
        "# Strategy 2: Replacing tokens with similar words considering POS tagging\n",
        "def replace_with_similar_human_word_pos(text, tokens_to_replace):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    replacements = {}\n",
        "    for idx, (token, pos) in enumerate(pos_tags):\n",
        "        if token in tokens_to_replace:\n",
        "            if token in human_model.wv:\n",
        "                similar_words = human_model.wv.most_similar(token, topn=10)\n",
        "                for similar_word, _ in similar_words:\n",
        "                    similar_pos = pos_tag([similar_word])[0][1]\n",
        "                    if similar_pos == pos:\n",
        "                        text = text.replace(token, similar_word, 1)\n",
        "                        replacements[token] = similar_word\n",
        "                        break\n",
        "    return text, replacements\n",
        "\n",
        "X_test_modified_2 = []\n",
        "replacements_strategy2 = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    text = X_test.iloc[i]['processed_text']\n",
        "    tokens_to_replace = influential_tokens[i]\n",
        "    modified_text, replacements = replace_with_similar_human_word_pos(text, tokens_to_replace)\n",
        "    X_test_modified_2.append(modified_text)\n",
        "    replacements_strategy2.append(replacements)\n",
        "\n",
        "# Strategy 3: Token Replacement using GPT-4\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    api_key = input(\"Please enter your OpenAI API key: \")\n",
        "\n",
        "openai.api_key = api_key\n",
        "\n",
        "def replace_tokens_with_gpt4(text, tokens_to_replace):\n",
        "    replacements = {}\n",
        "    for token in tokens_to_replace:\n",
        "        prompt = f\"Replace the token '{token}' with a more human-like word in the following text: '{text}'\"\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                #model=\"gpt-3.5-turbo\",\n",
        "                model=\"gpt-4o-mini\",\n",
        "\n",
        "                max_tokens=10,\n",
        "                n=1,\n",
        "                stop=None,\n",
        "                temperature=0.7,\n",
        "            )\n",
        "            replacement = response['choices'][0]['message']['content'].strip()\n",
        "            text = text.replace(token, replacement, 1)\n",
        "            replacements[token] = replacement\n",
        "        except Exception as e:\n",
        "            print(f\"Error replacing token '{token}': {e}\")\n",
        "    return text, replacements\n",
        "\n",
        "X_test_modified_3 = []\n",
        "replacements_strategy3 = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    text = X_test.iloc[i]['processed_text']\n",
        "    tokens_to_replace = influential_tokens[i]\n",
        "    modified_text, replacements = replace_tokens_with_gpt4(text, tokens_to_replace)\n",
        "    X_test_modified_3.append(modified_text)\n",
        "    replacements_strategy3.append(replacements)\n",
        "\n",
        "# Strategy 4: Using GPT-4 with genre-specific information\n",
        "def replace_tokens_with_gpt4_genre(text, tokens_to_replace, genre):\n",
        "    replacements = {}\n",
        "    for token in tokens_to_replace:\n",
        "        prompt = f\"Replace the token '{token}' with a more human-like word in the following {genre} text: '{text}'\"\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                #model=\"gpt-3.5-turbo\",\n",
        "                model=\"gpt-4o-mini\",\n",
        "                max_tokens=10,\n",
        "                n=1,\n",
        "                stop=None,\n",
        "                temperature=0.7,\n",
        "            )\n",
        "            replacement = response['choices'][0]['message']['content'].strip()\n",
        "            text = text.replace(token, replacement, 1)\n",
        "            replacements[token] = replacement\n",
        "        except Exception as e:\n",
        "            print(f\"Error replacing token '{token}': {e}\")\n",
        "    return text, replacements\n",
        "\n",
        "X_test_modified_4 = []\n",
        "replacements_strategy4 = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    text = X_test.iloc[i]['processed_text']\n",
        "    tokens_to_replace = influential_tokens[i]\n",
        "    genre = X_test.iloc[i]['domain']\n",
        "    modified_text, replacements = replace_tokens_with_gpt4_genre(text, tokens_to_replace, genre)\n",
        "    X_test_modified_4.append(modified_text)\n",
        "    replacements_strategy4.append(replacements)\n",
        "\n",
        "# Test the model on the revised texts\n",
        "X_test_modified_1_tfidf = vectorizer.transform(X_test_modified_1)\n",
        "X_test_modified_2_tfidf = vectorizer.transform(X_test_modified_2)\n",
        "X_test_modified_3_tfidf = vectorizer.transform(X_test_modified_3)\n",
        "X_test_modified_4_tfidf = vectorizer.transform(X_test_modified_4)\n",
        "\n",
        "y_pred_modified_1 = model.predict(X_test_modified_1_tfidf)\n",
        "y_pred_modified_2 = model.predict(X_test_modified_2_tfidf)\n",
        "y_pred_modified_3 = model.predict(X_test_modified_3_tfidf)\n",
        "y_pred_modified_4 = model.predict(X_test_modified_4_tfidf)\n",
        "\n",
        "# Evaluate the performance on modified texts\n",
        "def get_metrics_dict(y_true, y_pred, strategy_name):\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return {\n",
        "        'Strategy': strategy_name,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Accuracy': accuracy\n",
        "    }\n",
        "\n",
        "metrics_original = get_metrics_dict(y_test, y_pred, 'Original')\n",
        "metrics_strategy1 = get_metrics_dict(y_test, y_pred_modified_1, 'Strategy 1')\n",
        "metrics_strategy2 = get_metrics_dict(y_test, y_pred_modified_2, 'Strategy 2')\n",
        "metrics_strategy3 = get_metrics_dict(y_test, y_pred_modified_3, 'Strategy 3')\n",
        "metrics_strategy4 = get_metrics_dict(y_test, y_pred_modified_4, 'Strategy 4')\n",
        "\n",
        "metrics_all_strategies = pd.DataFrame([\n",
        "    metrics_original,\n",
        "    metrics_strategy1,\n",
        "    metrics_strategy2,\n",
        "    metrics_strategy3,\n",
        "    metrics_strategy4\n",
        "])\n",
        "\n",
        "# Plot comparison of strategies\n",
        "fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    sns.barplot(x='Strategy', y=metric, data=metrics_all_strategies, ax=ax[idx])\n",
        "    ax[idx].set_title(f'{metric} Comparison')\n",
        "    ax[idx].set_ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification reports for each strategy\n",
        "print(\"\\nResults for Strategy 1:\")\n",
        "print(classification_report(y_test, y_pred_modified_1, target_names=['human', 'generated']))\n",
        "\n",
        "print(\"\\nResults for Strategy 2:\")\n",
        "print(classification_report(y_test, y_pred_modified_2, target_names=['human', 'generated']))\n",
        "\n",
        "print(\"\\nResults for Strategy 3:\")\n",
        "print(classification_report(y_test, y_pred_modified_3, target_names=['human', 'generated']))\n",
        "\n",
        "print(\"\\nResults for Strategy 4:\")\n",
        "print(classification_report(y_test, y_pred_modified_4, target_names=['human', 'generated']))\n",
        "\n",
        "# Save the tokens that were replaced as well as the replacements and the final datasets\n",
        "def save_strategy_results(strategy_number, modified_texts, replacements):\n",
        "    results_df = pd.DataFrame({\n",
        "        'original_text': X_test['processed_text'],\n",
        "        'modified_text': modified_texts,\n",
        "        'replacements': replacements,\n",
        "        'true_label': y_test,\n",
        "        'pred_label': eval(f'y_pred_modified_{strategy_number}')\n",
        "    })\n",
        "    results_df.to_csv(f'strategy{strategy_number}_results.csv', index=False)\n",
        "\n",
        "save_strategy_results(1, X_test_modified_1, replacements_strategy1)\n",
        "save_strategy_results(2, X_test_modified_2, replacements_strategy2)\n",
        "save_strategy_results(3, X_test_modified_3, replacements_strategy3)\n",
        "save_strategy_results(4, X_test_modified_4, replacements_strategy4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained model\n",
        "with open('xgboost_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "# Save the TF-IDF vectorizer\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(vectorizer, vectorizer_file)"
      ],
      "metadata": {
        "id": "xcwp8lfMg1E6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}